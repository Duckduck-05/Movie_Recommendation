{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Packages\n",
    "Import dependences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll Skip this for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define class Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MF(object):\n",
    "#     \"\"\"docstring for CF\"\"\"\n",
    "#     def __init__(self, Y_data, K, lam = 0.1, Xinit = None, Winit = None, \n",
    "#             learning_rate = 0.5, max_iter = 1000, print_every = 100, user_based = 1):\n",
    "#         self.Y_raw_data = Y_data\n",
    "#         self.K = K\n",
    "#         # regularization parameter\n",
    "#         self.lam = lam\n",
    "#         # learning rate for gradient descent\n",
    "#         self.learning_rate = learning_rate\n",
    "#         # maximum number of iterations\n",
    "#         self.max_iter = max_iter\n",
    "#         # print results after print_every iterations\n",
    "#         self.print_every = print_every\n",
    "#         # user-based or item-based\n",
    "#         self.user_based = user_based\n",
    "#         # number of users, items, and ratings. Remember to add 1 since id starts from 0\n",
    "#         self.n_users = int(np.max(Y_data[:, 0])) + 1 \n",
    "#         self.n_items = int(np.max(Y_data[:, 1])) + 1\n",
    "#         self.n_ratings = Y_data.shape[0]\n",
    "        \n",
    "#         if Xinit is None: # new\n",
    "#             self.X = np.random.randn(self.n_items, K)\n",
    "#         else: # or from saved data\n",
    "#             self.X = Xinit \n",
    "        \n",
    "#         if Winit is None: \n",
    "#             self.W = np.random.randn(K, self.n_users)\n",
    "#         else: # from daved data\n",
    "#             self.W = Winit\n",
    "            \n",
    "#         # normalized data, update later in normalized_Y function\n",
    "#         self.Y_data_n = self.Y_raw_data.copy()\n",
    "\n",
    "# # Function to normalize utility matrix\n",
    "#     def normalize_Y(self):\n",
    "#         if self.user_based:\n",
    "#             user_col = 0\n",
    "#             item_col = 1\n",
    "#             n_objects = self.n_users\n",
    "\n",
    "#         # if we want to normalize based on item, just switch first two columns of data\n",
    "#         else: # item bas\n",
    "#             user_col = 1\n",
    "#             item_col = 0 \n",
    "#             n_objects = self.n_items\n",
    "\n",
    "#         users = self.Y_raw_data[:, user_col] \n",
    "#         self.mu = np.zeros((n_objects,))\n",
    "#         for n in range(n_objects):\n",
    "#             # row indices of rating done by user n\n",
    "#             # since indices need to be integers, we need to convert\n",
    "#             ids = np.where(users == n)[0].astype(np.int32)\n",
    "#             # indices of all ratings associated with user n\n",
    "#             item_ids = self.Y_data_n[ids, item_col] \n",
    "#             # and the corresponding ratings \n",
    "#             ratings = self.Y_data_n[ids, 2]\n",
    "#             # take mean\n",
    "#             m = np.mean(ratings) \n",
    "#             if np.isnan(m):\n",
    "#                 m = 0 # to avoid empty array and nan value\n",
    "#             self.mu[n] = m\n",
    "#             # normalize\n",
    "#             self.Y_data_n[ids, 2] = ratings - self.mu[n]\n",
    "\n",
    "# # Loss Function\n",
    "#     def loss(self):\n",
    "#         L = 0 \n",
    "#         for i in range(self.n_ratings):\n",
    "#             # user, item, rating\n",
    "#             n, m, rate = int(self.Y_data_n[i, 0]), int(self.Y_data_n[i, 1]), self.Y_data_n[i, 2]\n",
    "#             L += 0.5*(rate - self.X[m, :].dot(self.W[:, n]))**2\n",
    "        \n",
    "#         # take average\n",
    "#         L /= self.n_ratings\n",
    "#         # regularization, don't ever forget this \n",
    "#         L += 0.5*self.lam*(np.linalg.norm(self.X, 'fro') + np.linalg.norm(self.W, 'fro'))\n",
    "#         return L \n",
    "\n",
    "\n",
    "# # Get items rated, and users have rated\n",
    "#     def get_items_rated_by_user(self, user_id):\n",
    "#         \"\"\"\n",
    "#         get all items which are rated by user user_id, and the corresponding ratings\n",
    "#         \"\"\"\n",
    "#         ids = np.where(self.Y_data_n[:,0] == user_id)[0] \n",
    "#         item_ids = self.Y_data_n[ids, 1].astype(np.int32) # indices need to be integers\n",
    "#         ratings = self.Y_data_n[ids, 2]\n",
    "#         return (item_ids, ratings)\n",
    "        \n",
    "        \n",
    "#     def get_users_who_rate_item(self, item_id):\n",
    "#         \"\"\"\n",
    "#         get all users who rated item item_id and get the corresponding ratings\n",
    "#         \"\"\"\n",
    "#         ids = np.where(self.Y_data_n[:,1] == item_id)[0] \n",
    "#         user_ids = self.Y_data_n[ids, 0].astype(np.int32)\n",
    "#         ratings = self.Y_data_n[ids, 2]\n",
    "#         return (user_ids, ratings)\n",
    "    \n",
    "\n",
    "# # Update Parameters\n",
    "#     def updateX(self):\n",
    "#         for m in range(self.n_items):\n",
    "#             user_ids, ratings = self.get_users_who_rate_item(m)\n",
    "#             Wm = self.W[:, user_ids]\n",
    "#             # gradient\n",
    "#             grad_xm = -(ratings - self.X[m, :].dot(Wm)).dot(Wm.T)/self.n_ratings + \\\n",
    "#                                                self.lam*self.X[m, :]\n",
    "#             self.X[m, :] -= self.learning_rate*grad_xm.reshape((self.K,))\n",
    "    \n",
    "#     def updateW(self):\n",
    "#         for n in range(self.n_users):\n",
    "#             item_ids, ratings = self.get_items_rated_by_user(n)\n",
    "#             Xn = self.X[item_ids, :]\n",
    "#             # gradient\n",
    "#             grad_wn = -Xn.T.dot(ratings - Xn.dot(self.W[:, n]))/self.n_ratings + \\\n",
    "#                         self.lam*self.W[:, n]\n",
    "#             self.W[:, n] -= self.learning_rate*grad_wn.reshape((self.K,))\n",
    "\n",
    "# # Run Model\n",
    "#     def fit(self):\n",
    "#         self.normalize_Y()\n",
    "#         for it in range(self.max_iter):\n",
    "#             self.updateX()\n",
    "#             self.updateW()\n",
    "#             if (it + 1) % self.print_every == 0:\n",
    "#                 rmse_train = self.evaluate_RMSE(self.Y_raw_data)\n",
    "#                 print('iter =', it + 1, ', loss =', self.loss(), ', RMSE train =', rmse_train)\n",
    "\n",
    "# # Make predictions\n",
    "#     def pred(self, u, i):\n",
    "#         \"\"\" \n",
    "#         predict the rating of user u for item i \n",
    "#         if you need the un\n",
    "#         \"\"\"\n",
    "#         u = int(u)\n",
    "#         i = int(i)\n",
    "#         if self.user_based:\n",
    "#             bias = self.mu[u]\n",
    "#         else: \n",
    "#             bias = self.mu[i]\n",
    "#         pred = self.X[i, :].dot(self.W[:, u]) + bias \n",
    "#         # truncate if results are out of range [0, 5]\n",
    "#         if pred < 0:\n",
    "#             return 0 \n",
    "#         if pred > 5: \n",
    "#             return 5 \n",
    "#         return pred \n",
    "        \n",
    "    \n",
    "#     def pred_for_user(self, user_id):\n",
    "#         \"\"\"\n",
    "#         predict ratings one user give all unrated items\n",
    "#         \"\"\"\n",
    "#         ids = np.where(self.Y_data_n[:, 0] == user_id)[0]\n",
    "#         items_rated_by_u = self.Y_data_n[ids, 1].tolist()              \n",
    "        \n",
    "#         y_pred = self.X.dot(self.W[:, user_id]) + self.mu[user_id]\n",
    "#         predicted_ratings= []\n",
    "#         for i in range(self.n_items):\n",
    "#             if i not in items_rated_by_u:\n",
    "#                 predicted_ratings.append((i, y_pred[i]))\n",
    "        \n",
    "#         return predicted_ratings\n",
    "    \n",
    "# # Root Mean Square Error\n",
    "#     def evaluate_RMSE(self, rate_test):\n",
    "#         n_tests = rate_test.shape[0]\n",
    "#         SE = 0 # squared error\n",
    "#         for n in range(n_tests):\n",
    "#             pred = self.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "#             SE += (pred - rate_test[n, 2])**2 \n",
    "\n",
    "#         RMSE = np.sqrt(SE/n_tests)\n",
    "#         return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on MovieLens100k Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "# ratings_base = pd.read_csv('ml-100k/ub.base', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "# ratings_test = pd.read_csv('ml-100k/ub.test', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "\n",
    "# rate_train = ratings_base.values\n",
    "# rate_test = ratings_test.values\n",
    "\n",
    "# # indices start from 0\n",
    "# rate_train[:, :2] -= 1\n",
    "# rate_test[:, :2] -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First 5 elements in rate_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rate_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalize based on users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = MF(rate_train, K = 10, lam = .1, print_every = 10, \n",
    "#     learning_rate = 0.75, max_iter = 100, user_based = 1)\n",
    "# rs.fit()\n",
    "# # evaluate on test data\n",
    "# RMSE = rs.evaluate_RMSE(rate_test)\n",
    "# print('\\nUser-based MF, RMSE =', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalize based on items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = MF(rate_train, K = 10, lam = .1, print_every = 10, learning_rate = 0.75, max_iter = 100, user_based = 0)\n",
    "# rs.fit()\n",
    "# # evaluate on test data\n",
    "# RMSE = rs.evaluate_RMSE(rate_test)\n",
    "# print('\\nItem-based MF, RMSE =', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without regularization to see how worse it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = MF(rate_train, K = 2, lam = 0, print_every = 10, learning_rate = 1, max_iter = 100, user_based = 0)\n",
    "# rs.fit()\n",
    "# # evaluate on test data\n",
    "# RMSE = rs.evaluate_RMSE(rate_test)\n",
    "# print('\\nItem-based MF, RMSE =', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try with SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVDMatrixFactorization:\n",
    "    \"\"\"\n",
    "    Matrix Factorization using Singular Value Decomposition (SVD)\n",
    "    Handles both user-based and item-based recommendation systems\n",
    "    \"\"\"\n",
    "    def __init__(self, Y_data, K, user_based=1):\n",
    "        \"\"\"\n",
    "        Initialize SVD Matrix Factorization\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        Y_data : numpy array\n",
    "            Rating data with columns [user_id, item_id, rating]\n",
    "        K : int\n",
    "            Number of latent factors\n",
    "        user_based : bool, optional (default=1)\n",
    "            Whether to use user-based or item-based approach\n",
    "        \"\"\"\n",
    "        self.Y_raw_data = Y_data\n",
    "        self.K = K  # Number of latent factors\n",
    "        self.user_based = user_based\n",
    "        # Determine number of users and items\n",
    "        self.n_users = int(np.max(Y_data[:, 0])) + 1\n",
    "        self.n_items = int(np.max(Y_data[:, 1])) + 1\n",
    "        \n",
    "        # Prepare rating matrix\n",
    "        self.rating_matrix = self._create_rating_matrix()\n",
    "        \n",
    "        # Normalized rating matrix and mean ratings\n",
    "        self.normalized_matrix, self.user_means = self._normalize_ratings()\n",
    "        \n",
    "    def _create_rating_matrix(self):\n",
    "        \"\"\"\n",
    "        Create a sparse rating matrix from raw data\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        numpy array\n",
    "            Rating matrix with users as rows and items as columns\n",
    "        \"\"\"\n",
    "        # Initialize rating matrix with zeros\n",
    "        rating_matrix = np.zeros((self.n_users, self.n_items))\n",
    "        \n",
    "        # Fill matrix with ratings\n",
    "        for user, item, rating in self.Y_raw_data:\n",
    "            rating_matrix[int(user), int(item)] = rating\n",
    "        \n",
    "        return rating_matrix\n",
    "    \n",
    "    def _normalize_ratings(self):\n",
    "        \"\"\"\n",
    "        Normalize ratings by subtracting user means\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple: (normalized_matrix, user_means)\n",
    "        \"\"\"\n",
    "        # Calculate mean ratings for each user\n",
    "        user_means = np.zeros(self.n_users)\n",
    "        normalized_matrix = self.rating_matrix.copy()\n",
    "        \n",
    "        for user in range(self.n_users):\n",
    "            # Get user's rated items\n",
    "            rated_items = normalized_matrix[user, :] > 0\n",
    "            \n",
    "            if np.sum(rated_items) > 0:\n",
    "                # Calculate mean of rated items\n",
    "                user_means[user] = np.mean(normalized_matrix[user, rated_items])\n",
    "                \n",
    "                # Subtract mean from rated items\n",
    "                normalized_matrix[user, rated_items] -= user_means[user]\n",
    "        \n",
    "        return normalized_matrix, user_means\n",
    "    \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Perform SVD decomposition on normalized rating matrix\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        self: Fitted model with decomposed matrices\n",
    "        \"\"\"\n",
    "        # Perform SVD on normalized matrix\n",
    "        U, sigma, VT = np.linalg.svd(self.normalized_matrix, full_matrices=False)\n",
    "        \n",
    "        # Truncate to K latent factors\n",
    "        U_reduced = U[:, :self.K]\n",
    "        sigma_reduced = np.diag(sigma[:self.K])\n",
    "        VT_reduced = VT[:self.K, :]\n",
    "        \n",
    "        # Store decomposed matrices\n",
    "        self.U = U_reduced\n",
    "        self.sigma = sigma_reduced\n",
    "        self.VT = VT_reduced\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def pred(self, user, item):\n",
    "        \"\"\"\n",
    "        Predict rating for a specific user-item pair\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        user : int\n",
    "            User ID\n",
    "        item : int\n",
    "            Item ID\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        float: Predicted rating\n",
    "        \"\"\"\n",
    "        # Reconstruct rating using SVD components\n",
    "        # Reconstruct with top K singular values\n",
    "        reconstructed_rating = np.dot(\n",
    "            np.dot(self.U[user, :], self.sigma), \n",
    "            self.VT[:, item]\n",
    "        )\n",
    "        \n",
    "        # Add back user mean\n",
    "        predicted_rating = reconstructed_rating + self.user_means[user]\n",
    "        \n",
    "        # Clip rating to valid range\n",
    "        return np.clip(predicted_rating, 0, 5)\n",
    "    \n",
    "    def pred_for_user(self, user_id):\n",
    "        \"\"\"\n",
    "        Predict ratings for all unrated items for a user\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        user_id : int\n",
    "            User ID to predict ratings for\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        list: Predicted (item_id, rating) pairs\n",
    "        \"\"\"\n",
    "        # Get items already rated by the user\n",
    "        rated_items = np.where(self.rating_matrix[user_id, :] > 0)[0]\n",
    "        \n",
    "        # Predict ratings for unrated items\n",
    "        predicted_ratings = []\n",
    "        for item in range(self.n_items):\n",
    "            if item not in rated_items:\n",
    "                pred_rating = self.pred(user_id, item)\n",
    "                predicted_ratings.append((item, pred_rating))\n",
    "        \n",
    "        return predicted_ratings\n",
    "\n",
    "    def evaluate_RMSE(self, rate_test):\n",
    "        \"\"\"\n",
    "        Calculate Root Mean Square Error on test data\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        rate_test : numpy array\n",
    "            Test ratings data\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        float: RMSE value\n",
    "        \"\"\"\n",
    "        n_tests = rate_test.shape[0]\n",
    "        SE = 0  # Squared Error\n",
    "        \n",
    "        for n in range(n_tests):\n",
    "            pred = self.pred(int(rate_test[n, 0]), int(rate_test[n, 1]))\n",
    "            SE += (pred - rate_test[n, 2])**2 \n",
    "        \n",
    "        RMSE = np.sqrt(SE/n_tests)\n",
    "        return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's run on MovieLens100k Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "ratings_base = pd.read_csv('../data/ml-100k/ub.base', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv('../data/ml-100k/ub.test', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "\n",
    "rate_train = ratings_base.values\n",
    "rate_test = ratings_test.values\n",
    "\n",
    "# indices start from 0\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1\n",
    "# Remove timnestamp for training proceess\n",
    "rate_train = rate_train[:,:-1]\n",
    "rate_test = rate_test[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 5],\n",
       "       [0, 1, 3],\n",
       "       [0, 2, 4],\n",
       "       [0, 3, 3],\n",
       "       [0, 4, 3]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First five elements\n",
    "rate_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_set_raw = pd.read_csv(\"../data/ml-100k/u.item\", encoding=\"latin-1\", sep=\"|\", names=[\"id\", \"name\", \"col3\", \"col4\", \"col5\", \"col6\", \"col7\", \"col8\", \"col9\", \"col10\", \"col11\", \"col12\", \"col13\", \"col14\", \"col15\", \"col16\", \"col17\", \"col18\", \"col19\", \"col20\", \"col21\", \"col22\", \"col23\", \"col24\"])\n",
    "\n",
    "movies_set = movies_set_raw.iloc[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs_svd = SVDMatrixFactorization(rate_train, K = 5, user_based=1)\n",
    "# rs_svd.fit()\n",
    "# # evaluate on test data\n",
    "# RMSE_svd = rs_svd.evaluate_RMSE(rate_test)\n",
    "# print('\\nMF with SVD, RMSE =', RMSE_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs_svd = SVDMatrixFactorization(rate_train, K = 5, user_based=0)\n",
    "# rs_svd.fit()\n",
    "# # evaluate on test data\n",
    "# RMSE_svd = rs_svd.evaluate_RMSE(rate_test)\n",
    "# print('\\nMF with SVD, RMSE =', RMSE_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now let's recommend the top 10 must watch movies\n",
    "\n",
    "1. for new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MF with SVD, K = 500 , RMSE = 1.0594251736343696\n",
      "\n",
      "MF with SVD, K = 100, RMSE = 1.033888535270703\n",
      "\n",
      "MF with SVD, K = 200, RMSE = 1.048198727924585\n",
      "\n",
      "MF with SVD, K = 1000, RMSE = 1.0603799056362448\n"
     ]
    }
   ],
   "source": [
    "rs_svd = SVDMatrixFactorization(rate_train, K = 500, user_based=0)\n",
    "rs_svd.fit()\n",
    "RMSE_svd = rs_svd.evaluate_RMSE(rate_test)\n",
    "print('\\nMF with SVD, K = 500 , RMSE =', RMSE_svd)\n",
    "rs_svd = SVDMatrixFactorization(rate_train, K = 100, user_based=0)\n",
    "rs_svd.fit()\n",
    "RMSE_svd = rs_svd.evaluate_RMSE(rate_test)\n",
    "print('\\nMF with SVD, K = 100, RMSE =', RMSE_svd)\n",
    "rs_svd = SVDMatrixFactorization(rate_train, K = 200, user_based=0)\n",
    "rs_svd.fit()\n",
    "RMSE_svd = rs_svd.evaluate_RMSE(rate_test)\n",
    "print('\\nMF with SVD, K = 200, RMSE =', RMSE_svd)\n",
    "rs_svd = SVDMatrixFactorization(rate_train, K = 1000, user_based=0)\n",
    "rs_svd.fit()\n",
    "RMSE_svd = rs_svd.evaluate_RMSE(rate_test)\n",
    "print('\\nMF with SVD, K = 1000, RMSE =', RMSE_svd)\n",
    "# rcm = rs_svd.recommend_new_user(top_n=10)\n",
    "# print(\"Top 10 Must Watch Movie:\")\n",
    "# idx = 1\n",
    "# for i in rcm:\n",
    "#     print(str(idx) + \". \" + i)\n",
    "#     idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now let's run with the 2018 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_set_2018_raw = pd.read_csv(\"ml-latest-small/movies.csv\", encoding='latin-1')\n",
    "# movies_set_2018 = movies_set_2018_raw.drop(['genres'],axis=1)\n",
    "# movies_set_2018.rename(columns={'movieId': 'id', 'title':'name'},inplace=True)\n",
    "# movies_set_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest_df = pd.read_csv(\"ml-latest-small/ratings.csv\")\n",
    "# latest_df_arr = latest_df.values[:,:-1]\n",
    "# latest_df_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seperate train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# rate_train_2018, rate_test_2018 = train_test_split(latest_df_arr, test_size=0.33, random_state=42)\n",
    "# print(rate_train_2018.shape, rate_test_2018.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_svd_2 = SVDMatrixFactorization(rate_train_2018, K=10, movies_set=movies_set_2018, user_based=0)\n",
    "# model_svd_2.fit()\n",
    "\n",
    "# RMSE_svd_2018 = model_svd_2.evaluate_RMSE(rate_test_2018)\n",
    "# print('\\nMF with SVD, RMSE =', RMSE_svd_2018)\n",
    "\n",
    "# # rcm2 = model_svd_2.recommend_new_user(top_n=10)\n",
    "# # print(\"Top 10 Must Watch Movie:\")\n",
    "# # idx = 1\n",
    "# # for i in rcm2:\n",
    "# #     print(str(idx) + \". \" + i)\n",
    "# #     idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcm2 = model_svd_2.rec_new_user(top_n=10)\n",
    "# print(\"Top 10 Must Watch Movie:\")\n",
    "# # idx = 1\n",
    "# # for i in rcm2:\n",
    "# #     print(str(idx) + \". \" + i)\n",
    "# #     idx += 1\n",
    "# rcm2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
